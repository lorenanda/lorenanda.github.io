<!DOCTYPE html>
<html lang="en">
<!-- Beautiful Jekyll 5.0.0 | Copyright Dean Attali 2020 -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  

  <title>Detecting emotions from speech with neural networks</title>

  
  <meta name="author" content="Lorena Ciutacu">
  

  <meta name="description" content="Project completed in week 12 (14.12.-18.12.20) of the Data Science Bootcamp at Spiced Academy in Berlin. I did it! I graduated from the Data Science Bootcamp! On Friday I presented my final project, which was about detecting emotions from speech with neural networks. It was one of the most challenging...">

  

  
  <meta name="keywords" content="data scientist, women in data, linguistics research projects, buchrezensionen, berlin startup">
  

  <link rel="alternate" type="application/rss+xml" title="Lorena Ciutacu" href="http://localhost:4000/feed.xml">

  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0B4RTHP9QL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-0B4RTHP9QL');
</script>


  

  
<!-- Google Analytics -->
<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-119170762-2', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/beautifuljekyll.css">
    
  

  

  
  
  

  

  
  <meta property="og:site_name" content="Lorena Ciutacu">
  <meta property="og:title" content="Detecting emotions from speech with neural networks">
  <meta property="og:description" content="Project completed in week 12 (14.12.-18.12.20) of the Data Science Bootcamp at Spiced Academy in Berlin. I did it! I graduated from the Data Science Bootcamp! On Friday I presented my final project, which was about detecting emotions from speech with neural networks. It was one of the most challenging...">

  

  
  <meta property="og:type" content="article">
  <meta property="og:article:author" content="Lorena Ciutacu">
  <meta property="og:article:published_time" content="2020-12-20T00:00:00+01:00">
  <meta property="og:url" content="http://localhost:4000/2020-12-20-bootcamp12/">
  <link rel="canonical" href="http://localhost:4000/2020-12-20-bootcamp12/">
  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:site" content="@alciutacu">
  <meta name="twitter:creator" content="@alciutacu">

  <meta property="twitter:title" content="Detecting emotions from speech with neural networks">
  <meta property="twitter:description" content="Project completed in week 12 (14.12.-18.12.20) of the Data Science Bootcamp at Spiced Academy in Berlin. I did it! I graduated from the Data Science Bootcamp! On Friday I presented my final project, which was about detecting emotions from speech with neural networks. It was one of the most challenging...">

  

  


  

  

  
</head>


<body>

  


  <nav class="navbar navbar-expand-xl navbar-light fixed-top navbar-custom top-nav-regular"><a class="navbar-brand" href="http://localhost:4000/">Lorena Ciutacu</a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="/about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="/work">Work</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="/tags">Archive</a>
          </li></ul>
  </div>

  

  

</nav>


  <!-- TODO this file has become a mess, refactor it -->







<header class="header-section ">

<div class="intro-header no-img">
  <div class="container-md">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
        <div class="post-heading">
          <h1>Detecting emotions from speech with neural networks</h1>
          

          
            <span class="post-meta">Posted on December 20, 2020</span>
            
            
          
        </div>
      </div>
    </div>
  </div>
</div>
</header>





<div class=" container-md ">
  <div class="row">
    <div class=" col-xl-8 offset-xl-2 col-lg-10 offset-lg-1 ">

      
        
        
        

        <div id="header-gh-btns">
          
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=lorenanda&repo=speech-emotion-recognition&type=star&count=true" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=lorenanda&repo=speech-emotion-recognition&type=fork&count=true" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=lorenanda&type=follow&count=true" frameborder="0" scrolling="0" width="220px" height="20px"></iframe>
              
            
          
        </div>
      

      

      <article role="main" class="blog-post">
        <blockquote>
  <p>Project completed in week 12 (14.12.-18.12.20) of the Data Science Bootcamp at Spiced Academy in Berlin.</p>
</blockquote>

<p>I did it! I graduated from the Data Science Bootcamp! On Friday I presented my final project, which was about detecting emotions from speech with neural networks. It was one of the most challenging project I’ve worked on, because I had to learn something new (how to process audio data and make live voice predictions) and prepare everything nicely in only 7 days. Here’s how it went…</p>

<details>
    <summary><strong>Table of contents</strong></summary>
    <a href="#project-planning">Project planning</a><br />
    <a href="#data-set">Data set</a><br />
    &nbsp;&nbsp;&nbsp;<a href="#oversampling">Oversampling</a><br />
    &nbsp;&nbsp;&nbsp;<a href="#feature-extraction">Feature extraction</a><br />
    <a href="#machine-learning-models">Machine Learning models</a><br />
    <a href="#predictions">Predictions</a><br />
    <a href="#next-steps">Next steps</a>
</details>

<h2 id="project-planning">Project planning</h2>

<p>First and foremost, I designed a project plan, after having a brief look at the data set. From my work experience and the assignments completed in the past three months, I’ve learned that this step is crucial for the success of a coding project. Planning helps me (and the team) organize my ideas, break down the big project into smaller tasks, identify issues, and track the progress – and not despair at the amount of work to be done in a short time.</p>

<p>For this purpose, I created a simple <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjEp7_GwP_tAhXD6aQKHXP5ClMQFjAAegQIAhAC&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FKanban_(development)&amp;usg=AOvVaw2B54c6DIMX8rua56XtMTP9">Kanban board</a> directly in the GitHub repository of my project, so that I have the code and tasks in one place.</p>

<figure><img src="https://lorenaciutacu.files.wordpress.com/2021/01/screenshot_2020-12-11-lorenanda-speech-emotion-recognition.png" alt="Project board in GitHub" width="100%" height="auto" style="width: 100%; height: auto !important; max-width:960px;-ms-interpolation-mode: bicubic;" /><figcaption><em>Project board in GitHub</em></figcaption></figure>

<p>To create a project board linked to a repository in GitHub:</p>
<ol>
  <li>In your desired repository, click on the tab <code class="language-plaintext highlighter-rouge">Projects</code>, then on <code class="language-plaintext highlighter-rouge">Create project</code>.</li>
  <li>Enter the <code class="language-plaintext highlighter-rouge">Project board name</code>.</li>
  <li>(Optional) Enter a <code class="language-plaintext highlighter-rouge">Description</code> of the project and select a <code class="language-plaintext highlighter-rouge">Project template</code>.</li>
  <li>Click on <code class="language-plaintext highlighter-rouge">Create project</code>.</li>
</ol>

<h2 id="data-set">Data set</h2>

<p>I used the <strong>RAVDESS data set</strong>, which contains 1440 audio files. These are voice recordings of 24 actors (12 male, 12 female) who say two sentences in two different intensities (normal and strong) with eight intonations that express different emotions: calm, happy, sad, angry, fearful, surprised, disgusted, and neutral. There are 192 recordings for each emotion, except for neutral, which doesn’t have recordings in strong intensity.</p>

<p>To sum up, the original RAVDESS data set includes:</p>

<ul>
  <li>1440 recordings</li>
  <li>24 speakers</li>
  <li>12 male, 12 female</li>
  <li>2 sentences</li>
  <li>2 intensities</li>
  <li>8 intonations / emotions</li>
  <li>192 recordings for 7 emotions</li>
  <li>96 recordings for 1 emotion</li>
</ul>

<figure><img src="https://lorenaciutacu.files.wordpress.com/2020/12/plot_emotions.png" alt="RAVDESS data set distribution" width="100%" height="auto" style="width: 100%; height: auto !important; max-width:960px;-ms-interpolation-mode: bicubic;" /><figcaption><em>RAVDESS data set distribution</em></figcaption></figure>

<h3 id="oversampling">Oversampling</h3>
<p>The data set was imbalanced, so I used the <code class="language-plaintext highlighter-rouge">RandomOversample</code> method to create new features for the neutral class.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">oversample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"speech_emotion_recognition/features/X.joblib"</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"speech_emotion_recognition/features/y.joblib"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> 

    <span class="n">oversample</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="s">"minority"</span><span class="p">)</span>
    <span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span> <span class="o">=</span> <span class="n">oversample</span><span class="p">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">X_over_save</span><span class="p">,</span> <span class="n">y_over_save</span> <span class="o">=</span> <span class="s">"X_over.joblib"</span><span class="p">,</span> <span class="s">"y_over.joblib"</span>
    <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">X_over</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">"speech_emotion_recognition/features/"</span><span class="p">,</span> <span class="n">X_over_save</span><span class="p">))</span>
    <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">y_over</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">"speech_emotion_recognition/features/"</span><span class="p">,</span> <span class="n">y_over_save</span><span class="p">))</span>
</code></pre></div></div>

<p>Oversampling added 96 new datapoints, so in the end I had <strong>1536 audio files</strong> to work with.</p>

<p>Another imbalance was gender-related: there were slightly more recordings by males and in normal intensity. I didn’t deal with this imbalance because it wasn’t significant to my project, since I only wanted to predict the emotion. However, it would be interesting to explore in the future.</p>

<h3 id="feature-extraction">Feature extraction</h3>
<p>There are many features that can be extracted from audio files, but I decided to work with the <strong>Mel Frequency Cepstral Coefficient (MFCC)</strong>.</p>

<blockquote>
  <p>Mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an MFC.</p>

  <p>The difference between the cepstrum and the mel-frequency cepstrum is that in the MFC, the frequency bands are equally spaced on the mel scale, which approximates the human auditory system’s response more closely than the linearly-spaced frequency bands used in the normal spectrum. This frequency warping can allow for better representation of sound, for example, in audio compression.</p>

  <p><a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">source</a></p>
</blockquote>

<p>To extract the MFCC from the audio files, I used the Python library <a href="https://librosa.org/doc/latest/index.html"><code class="language-plaintext highlighter-rouge">librosa</code></a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">):</span>
    <span class="n">feature_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="nb">dir</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="n">walk</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="n">y_lib</span><span class="p">,</span> <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">load</span><span class="p">(</span>
                <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="nb">dir</span><span class="p">,</span> <span class="nb">file</span><span class="p">),</span> <span class="n">res_type</span><span class="o">=</span><span class="s">"kaiser_fast"</span>
            <span class="p">)</span>
            <span class="n">mfccs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="n">mfcc</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_lib</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">40</span><span class="p">).</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
            <span class="p">)</span>

            <span class="nb">file</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">file</span><span class="p">[</span><span class="mi">7</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">mfccs</span><span class="p">,</span> <span class="nb">file</span>
            <span class="n">feature_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"Data loaded in %s seconds."</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">feature_list</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">X_save</span><span class="p">,</span> <span class="n">y_save</span> <span class="o">=</span> <span class="s">"X.joblib"</span><span class="p">,</span> <span class="s">"y.joblib"</span>
    <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">X_save</span><span class="p">))</span>
    <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">y_save</span><span class="p">))</span>

    <span class="k">return</span> <span class="s">"Preprocessing completed."</span>
</code></pre></div></div>

<p>The visual representation of MFCC looks like this:</p>

<figure><img src="https://lorenaciutacu.files.wordpress.com/2020/12/mfcc1.png" alt="MFCC plot" width="100%" height="auto" style="width: 100%; height: auto !important; max-width:960px;-ms-interpolation-mode: bicubic;" /><figcaption><em>MFCC plot</em></figcaption></figure>

<h2 id="machine-learning-models">Machine Learning Models</h2>

<p>I trained three different neural networks models on the MFCC and emotion labels:</p>

<ul>
  <li><strong>Multi-Layer Perceptron (MLP)</strong> 
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mlp_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">mlp_model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
    <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,),</span>
    <span class="n">solver</span><span class="o">=</span><span class="s">"adam"</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">momentum</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Convolutional Neural Network (CNN)</strong>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cnn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">x_traincnn</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x_testcnn</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">"relu"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">"relu"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Conv1D</span><span class="p">(</span>
        <span class="mi">8</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">"relu"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">"relu"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">"softmax"</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="s">"categorical_crossentropy"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">,</span> 
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">cnn_history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x_traincnn</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_testcnn</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Long Short-Term Memory (LSTM)</strong>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">lstm_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="n">X_train_lstm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_test_lstm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">lstm_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">lstm_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">lstm_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
<span class="n">lstm_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">))</span>
<span class="n">lstm_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">lstm_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"softmax"</span><span class="p">))</span>

<span class="n">lstm_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">"categorical_crossentropy"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">lstm_model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">lstm_history</span> <span class="o">=</span> <span class="n">lstm_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lstm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
</ul>

<p>After several iterations of tweaking the hyperparameters, I found that generally the models performed better with low learning rates (0.001), <code class="language-plaintext highlighter-rouge">adam</code> optimizer, and less layers. All models overfit (they couldn’t generalize on unseen data), but this seems to be a common issue in neural networks and on audio data.</p>

<p>As expected, MLP had the lowest accuracy, since it’s a very basic model (a simple feed-forward artificial neural network). CNN and LSTM had similar train accuracy (80%), but CNN performed better on test data (60%) than LSTM (51%). To give you some context, state-of-the-art models for speech classification have an accuracy of 70-80%, so I was quite happy with my CNN model accuracy.</p>

<figure><img src="https://lorenaciutacu.files.wordpress.com/2020/12/models_accuracy.png" alt="Accuracy of different ML models" width="100%" height="auto" style="width: 100%; height: auto !important; max-width:960px;-ms-interpolation-mode: bicubic;" /><figcaption><em>Accuracy of different ML models</em></figcaption></figure>

<p>It was particularly interesting to look at the actual vs. predicted emotions, to see what emotions were misclassified. From the correlations matrices of CNN and LSTM, I noticed that both models misclassified emotions that sound similar or are ambiguous (even for humans), like sad-calm or angry-happy.</p>

<figure><img src="https://lorenaciutacu.files.wordpress.com/2020/12/lstm_confusionmatrix.png" alt="Confusion matrix of LSTM" width="100%" height="auto" style="width: 100%; height: auto !important; max-width:960px;-ms-interpolation-mode: bicubic;" /><figcaption><em>Confusion matrix of LSTM</em></figcaption></figure>

<figure><img src="https://lorenaciutacu.files.wordpress.com/2020/12/cnn_confusionmatrix.png" alt="Confusion matrix of CNN" width="100%" height="auto" style="width: 100%; height: auto !important; max-width:960px;-ms-interpolation-mode: bicubic;" /><figcaption><em>Confusion matrix of CNN</em></figcaption></figure>

<h2 id="predictions">Predictions</h2>

<p>The exciting part was to make predictions on new data, more specifically on <a href="http://www.moviesoundclips.net/">movie sound clips</a> and my own voice in real-time. To record my voice, I used the Python library <a href="https://python-sounddevice.readthedocs.io/en/0.4.1/"><code class="language-plaintext highlighter-rouge">sounddevice</code></a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">soundfile</span> <span class="k">as</span> <span class="n">sf</span>
<span class="kn">import</span> <span class="nn">sounddevice</span> <span class="k">as</span> <span class="n">sd</span>
<span class="kn">from</span> <span class="nn">scipy.io.wavfile</span> <span class="kn">import</span> <span class="n">write</span>


<span class="k">def</span> <span class="nf">record_voice</span><span class="p">():</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="mi">44100</span>  <span class="c1"># Sample rate
</span>    <span class="n">seconds</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Duration of recording
</span>    <span class="c1"># sd.default.device = "Built-in Audio"  # Speakers full name here
</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Say something:"</span><span class="p">)</span>
    <span class="n">myrecording</span> <span class="o">=</span> <span class="n">sd</span><span class="p">.</span><span class="n">rec</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">seconds</span> <span class="o">*</span> <span class="n">fs</span><span class="p">),</span> <span class="n">samplerate</span><span class="o">=</span><span class="n">fs</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sd</span><span class="p">.</span><span class="n">wait</span><span class="p">()</span>  <span class="c1"># Wait until recording is finished
</span>    <span class="n">write</span><span class="p">(</span><span class="s">"speech_emotion_recognition/recordings/myvoice.wav"</span><span class="p">,</span> <span class="n">fs</span><span class="p">,</span> <span class="n">myrecording</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Voice recording saved."</span><span class="p">)</span>
</code></pre></div></div>

<p>I then tested the CNN and LSTM models on pre- and live-recorded audio files:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_predictions</span><span class="p">(</span><span class="nb">file</span><span class="p">):</span>
    <span class="n">cnn_model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span>
        <span class="s">"speech_emotion_recognition/models/cnn_model.h5"</span>
    <span class="p">)</span>
    <span class="n">lstm_model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span>
        <span class="s">"speech_emotion_recognition/models/lstm_model.h5"</span>
    <span class="p">)</span>
    <span class="n">prediction_data</span><span class="p">,</span> <span class="n">prediction_sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">load</span><span class="p">(</span>
        <span class="nb">file</span><span class="p">,</span>
        <span class="n">res_type</span><span class="o">=</span><span class="s">"kaiser_fast"</span><span class="p">,</span>
        <span class="n">duration</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">sr</span><span class="o">=</span><span class="mi">22050</span><span class="p">,</span>
        <span class="n">offset</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span>
        <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="n">mfcc</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">prediction_data</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">prediction_sr</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">40</span><span class="p">).</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">mfccs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">lstm_model</span><span class="p">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">emotions_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"0"</span><span class="p">:</span> <span class="s">"neutral"</span><span class="p">,</span>
        <span class="s">"1"</span><span class="p">:</span> <span class="s">"calm"</span><span class="p">,</span>
        <span class="s">"2"</span><span class="p">:</span> <span class="s">"happy"</span><span class="p">,</span>
        <span class="s">"3"</span><span class="p">:</span> <span class="s">"sad"</span><span class="p">,</span>
        <span class="s">"4"</span><span class="p">:</span> <span class="s">"angry"</span><span class="p">,</span>
        <span class="s">"5"</span><span class="p">:</span> <span class="s">"fearful"</span><span class="p">,</span>
        <span class="s">"6"</span><span class="p">:</span> <span class="s">"disgusted"</span><span class="p">,</span>
        <span class="s">"7"</span><span class="p">:</span> <span class="s">"surprised"</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">emotions_dict</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">==</span> <span class="n">predictions</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"This voice sounds"</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</code></pre></div></div>

<p>Both models identified the correct or plausible emotion from recorded speech!</p>

<h2 id="next-steps">Next steps</h2>

<p>It was super exciting to work on this project and I’m already thinking of improving and extending it in some ways:</p>

<ul>
  <li>Try other models (not necessarily neural networks).</li>
  <li>Extract other audio features to see if they are better predictors than the MFCC.</li>
  <li>Train on larger data sets, since 1500 files and only 200 samples per emotion is not enough.</li>
  <li>Train on natural data, i.e. on recordings of people speaking in unstaged situations, so that the emotional speech sounds more realistic.</li>
  <li>Train on more diverse data, i.e. on recordings of people of different cultures and languages. This is important because the expression of emotions varies across cultures and is influenced also by individual experiences.</li>
  <li>Combine speech with facial expressions and text (speech-to-text) for multimodal sentiment analysis.</li>
</ul>

      </article>

      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript" ></script>

      
        <div class="blog-tags">
          <span>Tags:</span>
          
            <a href="/tags#data science">data science</a>
          
            <a href="/tags#projects">projects</a>
          
            <a href="/tags#bootcamp">bootcamp</a>
          
        </div>
      

      

      
        <!-- Check if any share-links are active -->




<section id = "social-share-section">
  <span class="sr-only">Share: </span>

  
    <a href="https://twitter.com/intent/tweet?text=Detecting+emotions+from+speech+with+neural+networks&url=http%3A%2F%2Flocalhost%3A4000%2F2020-12-20-bootcamp12%2F"
      class="btn btn-social-icon btn-twitter" title="Share on Twitter">
      <span class="fab fa-fw fa-twitter" aria-hidden="true"></span>
      <span class="sr-only">Twitter</span>
    </a>
  

  
    <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2F2020-12-20-bootcamp12%2F"
      class="btn btn-social-icon btn-facebook" title="Share on Facebook">
      <span class="fab fa-fw fa-facebook" aria-hidden="true"></span>
      <span class="sr-only">Facebook</span>
    </a>
  

  
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2F2020-12-20-bootcamp12%2F"
      class="btn btn-social-icon btn-linkedin" title="Share on LinkedIn">
      <span class="fab fa-fw fa-linkedin" aria-hidden="true"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  

  

</section>



      

      <ul class="pagination blog-pager">
        
        <li class="page-item previous">
          <a class="page-link" href="/2020-12-12-bootcamp11/" data-toggle="tooltip" data-placement="top" title="Best practices for software engineering">&larr; Best practices for software engineering</a>
        </li>
        
        
        <li class="page-item next">
          <a class="page-link" href="/2020-12-29-my-year-in-code/" data-toggle="tooltip" data-placement="top" title="My year in code - 2020 review">My year in code - 2020 review &rarr;</a>
        </li>
        
      </ul>
      
  
  
  

  




    </div>
  </div>
</div>


  <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
      <ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a href="https://linkedin.com/in/lorena-ciutacu" title="LinkedIn">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">LinkedIn</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://github.com/lorenanda" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://medium.com/@lorenaciutacu" title="Medium">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-medium fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Medium</span>
    </a>
  </li><li class="list-inline-item">
    <a href="https://twitter.com/alciutacu" title="Twitter">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Twitter</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://deviantart.com/dontstopnow" title="DeviantArt">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-deviantart fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">DeviantArt</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://www.goodreads.com/lorenasbooks" title="Goodreads">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-goodreads fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Goodreads</span>
   </a>
  </li></ul>

      
      <p class="copyright text-muted">
      
        Lorena Ciutacu
        &nbsp;&bull;&nbsp;
      
      2021

      

      

      </div>
    </div>
  </div>
</footer>


  
  
    
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/beautifuljekyll.js"></script>
    
  









</body>
</html>
